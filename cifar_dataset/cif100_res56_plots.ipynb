{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf \n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse \n",
    "import importlib\n",
    "# print(\"Importing supporting files\")\n",
    "# import keras_template_resnet\n",
    "# print(\"Successful\")\n",
    "\n",
    "# all function definitions \n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=100):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tensorflow.keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=100):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = tensorflow.keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version=2\n",
    "num_classes=100\n",
    "data_augmentation= True\n",
    "epochs=50\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num=6\n",
    "epochs = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "Model type is : ResNet56v2\n",
      "****************************************************\n",
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   272         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   1088        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 64)   1088        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 32, 32, 64)   0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 64)   256         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 16)   1040        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 16)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 64)   1088        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 64)   0           add[0][0]                        \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 64)   256         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 16)   1040        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 16)   64          conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 16)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 16)   2320        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 16)   64          conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 16)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 64)   1088        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 32, 32, 64)   0           add_1[0][0]                      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 64)   256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 16)   1040        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 16)   64          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 16)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 16)   2320        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 16)   64          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 16)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 64)   1088        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 32, 64)   0           add_2[0][0]                      \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 64)   256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 16)   1040        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 16)   64          conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 16)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 16)   2320        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 16)   64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 16)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 64)   1088        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 32, 32, 64)   0           add_3[0][0]                      \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 64)   256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 16)   1040        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 16)   64          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 16)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 16)   2320        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 16)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 64)   1088        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 32, 32, 64)   0           add_4[0][0]                      \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 64)   256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 64)   4160        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   256         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   36928       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 64)   256         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 128)  8320        add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 128)  8320        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 16, 16, 128)  0           conv2d_23[0][0]                  \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 128)  512         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 128)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 64)   8256        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   256         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   36928       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 64)   256         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 128)  8320        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 16, 16, 128)  0           add_6[0][0]                      \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 128)  512         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 128)  0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   8256        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   256         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 64)   36928       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 128)  8320        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 16, 16, 128)  0           add_7[0][0]                      \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 128)  512         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 128)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 64)   8256        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 64)   256         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 64)   36928       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 64)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 128)  8320        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 16, 16, 128)  0           add_8[0][0]                      \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 128)  512         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 128)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 64)   8256        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 64)   256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 64)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 64)   36928       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 64)   256         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 128)  8320        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 16, 16, 128)  0           add_9[0][0]                      \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 128)  512         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 64)   8256        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 64)   256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 64)   0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 64)   36928       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 64)   256         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 64)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 128)  8320        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 16, 16, 128)  0           add_10[0][0]                     \n",
      "                                                                 conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 128)  512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 8, 8, 128)    16512       activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 8, 8, 128)    512         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 8, 8, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 8, 8, 128)    147584      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 8, 8, 128)    512         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 8, 8, 128)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 8, 8, 256)    33024       add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 8, 8, 256)    33024       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 8, 8, 256)    0           conv2d_42[0][0]                  \n",
      "                                                                 conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 8, 8, 256)    1024        add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 8, 8, 256)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 8, 8, 128)    32896       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 8, 8, 128)    512         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 8, 8, 128)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 8, 8, 128)    147584      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 8, 8, 128)    512         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 8, 8, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 8, 8, 256)    33024       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 8, 8, 256)    0           add_12[0][0]                     \n",
      "                                                                 conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 8, 8, 256)    1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 8, 8, 256)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 8, 8, 128)    32896       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 8, 8, 128)    512         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 8, 8, 128)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 8, 8, 128)    147584      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 8, 8, 128)    512         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 8, 8, 128)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 8, 8, 256)    33024       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 8, 8, 256)    0           add_13[0][0]                     \n",
      "                                                                 conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 8, 8, 256)    1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 8, 8, 256)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 8, 8, 128)    32896       activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 8, 8, 128)    512         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 8, 8, 128)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 8, 8, 128)    147584      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 8, 8, 128)    512         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 8, 8, 128)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 8, 8, 256)    33024       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 8, 8, 256)    0           add_14[0][0]                     \n",
      "                                                                 conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 8, 8, 256)    1024        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 8, 8, 256)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 128)    32896       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 8, 8, 128)    512         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 8, 8, 128)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 128)    147584      activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 8, 8, 128)    512         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 8, 8, 128)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 256)    33024       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 8, 8, 256)    0           add_15[0][0]                     \n",
      "                                                                 conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 256)    1024        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 256)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 128)    32896       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 128)    512         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 128)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 128)    147584      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 128)    512         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 128)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 256)    33024       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 8, 8, 256)    0           add_16[0][0]                     \n",
      "                                                                 conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 256)    1024        add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 256)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 256)    0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 256)          0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          25700       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,696,868\n",
      "Trainable params: 1,686,468\n",
      "Non-trainable params: 10,400\n",
      "__________________________________________________________________________________________________\n",
      "ResNet56v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 62s 36ms/step - loss: 4.8480 - accuracy: 0.0955 - val_loss: 4.1290 - val_accuracy: 0.1538\n",
      "\n",
      "The average loss for epoch 0 is    4.35 and accuracy is    0.14.\n",
      "\n",
      "Epoch 00001: accuracy improved from -inf to 0.14106, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.001.h5\n",
      "Epoch 2/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 3.5340 - accuracy: 0.2354 - val_loss: 3.5663 - val_accuracy: 0.2342\n",
      "\n",
      "The average loss for epoch 1 is    3.40 and accuracy is    0.25.\n",
      "\n",
      "Epoch 00002: accuracy improved from 0.14106 to 0.25496, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.002.h5\n",
      "Epoch 3/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 3.0527 - accuracy: 0.3132 - val_loss: 3.3026 - val_accuracy: 0.2854\n",
      "\n",
      "The average loss for epoch 2 is    3.00 and accuracy is    0.33.\n",
      "\n",
      "Epoch 00003: accuracy improved from 0.25496 to 0.32516, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.003.h5\n",
      "Epoch 4/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.7758 - accuracy: 0.3738 - val_loss: 2.8543 - val_accuracy: 0.3652\n",
      "\n",
      "The average loss for epoch 3 is    2.75 and accuracy is    0.38.\n",
      "\n",
      "Epoch 00004: accuracy improved from 0.32516 to 0.38056, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.004.h5\n",
      "Epoch 5/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.5779 - accuracy: 0.4199 - val_loss: 2.7491 - val_accuracy: 0.3915\n",
      "\n",
      "The average loss for epoch 4 is    2.56 and accuracy is    0.42.\n",
      "\n",
      "Epoch 00005: accuracy improved from 0.38056 to 0.42216, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.005.h5\n",
      "Epoch 6/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.4431 - accuracy: 0.4471 - val_loss: 2.9076 - val_accuracy: 0.3767\n",
      "\n",
      "The average loss for epoch 5 is    2.42 and accuracy is    0.45.\n",
      "\n",
      "Epoch 00006: accuracy improved from 0.42216 to 0.45254, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.006.h5\n",
      "Epoch 7/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.3254 - accuracy: 0.4778 - val_loss: 2.6848 - val_accuracy: 0.4196\n",
      "\n",
      "The average loss for epoch 6 is    2.31 and accuracy is    0.48.\n",
      "\n",
      "Epoch 00007: accuracy improved from 0.45254 to 0.48110, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.007.h5\n",
      "Epoch 8/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.2201 - accuracy: 0.5000 - val_loss: 2.7685 - val_accuracy: 0.3997\n",
      "\n",
      "The average loss for epoch 7 is    2.21 and accuracy is    0.50.\n",
      "\n",
      "Epoch 00008: accuracy improved from 0.48110 to 0.50488, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.008.h5\n",
      "Epoch 9/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 2.1312 - accuracy: 0.5207 - val_loss: 3.0365 - val_accuracy: 0.3698\n",
      "\n",
      "The average loss for epoch 8 is    2.14 and accuracy is    0.52.\n",
      "\n",
      "Epoch 00009: accuracy improved from 0.50488 to 0.52228, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.009.h5\n",
      "Epoch 10/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.0770 - accuracy: 0.5395 - val_loss: 2.4148 - val_accuracy: 0.4845\n",
      "\n",
      "The average loss for epoch 9 is    2.07 and accuracy is    0.54.\n",
      "\n",
      "Epoch 00010: accuracy improved from 0.52228 to 0.54132, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.010.h5\n",
      "Epoch 11/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 2.0023 - accuracy: 0.5547 - val_loss: 2.6171 - val_accuracy: 0.4526\n",
      "\n",
      "The average loss for epoch 10 is    2.02 and accuracy is    0.55.\n",
      "\n",
      "Epoch 00011: accuracy improved from 0.54132 to 0.55374, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.011.h5\n",
      "Epoch 12/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.9487 - accuracy: 0.5728 - val_loss: 2.2967 - val_accuracy: 0.5031\n",
      "\n",
      "The average loss for epoch 11 is    1.97 and accuracy is    0.57.\n",
      "\n",
      "Epoch 00012: accuracy improved from 0.55374 to 0.56736, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.012.h5\n",
      "Epoch 13/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.9029 - accuracy: 0.5843 - val_loss: 2.5023 - val_accuracy: 0.4760\n",
      "\n",
      "The average loss for epoch 12 is    1.92 and accuracy is    0.58.\n",
      "\n",
      "Epoch 00013: accuracy improved from 0.56736 to 0.58008, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.013.h5\n",
      "Epoch 14/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.8769 - accuracy: 0.5861 - val_loss: 2.2732 - val_accuracy: 0.5193\n",
      "\n",
      "The average loss for epoch 13 is    1.88 and accuracy is    0.59.\n",
      "\n",
      "Epoch 00014: accuracy improved from 0.58008 to 0.58878, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.014.h5\n",
      "Epoch 15/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 1.8431 - accuracy: 0.6013 - val_loss: 2.1385 - val_accuracy: 0.5421\n",
      "\n",
      "The average loss for epoch 14 is    1.85 and accuracy is    0.60.\n",
      "\n",
      "Epoch 00015: accuracy improved from 0.58878 to 0.59940, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.015.h5\n",
      "Epoch 16/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 1.7837 - accuracy: 0.6129 - val_loss: 2.6631 - val_accuracy: 0.4905\n",
      "\n",
      "The average loss for epoch 15 is    1.81 and accuracy is    0.61.\n",
      "\n",
      "Epoch 00016: accuracy improved from 0.59940 to 0.60886, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.016.h5\n",
      "Epoch 17/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.7609 - accuracy: 0.6204 - val_loss: 2.3246 - val_accuracy: 0.5215\n",
      "\n",
      "The average loss for epoch 16 is    1.79 and accuracy is    0.61.\n",
      "\n",
      "Epoch 00017: accuracy improved from 0.60886 to 0.61388, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.017.h5\n",
      "Epoch 18/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.7346 - accuracy: 0.6315 - val_loss: 2.5960 - val_accuracy: 0.4726\n",
      "\n",
      "The average loss for epoch 17 is    1.75 and accuracy is    0.63.\n",
      "\n",
      "Epoch 00018: accuracy improved from 0.61388 to 0.62610, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.018.h5\n",
      "Epoch 19/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.7119 - accuracy: 0.6327 - val_loss: 2.3611 - val_accuracy: 0.5303\n",
      "\n",
      "The average loss for epoch 18 is    1.73 and accuracy is    0.63.\n",
      "\n",
      "Epoch 00019: accuracy improved from 0.62610 to 0.62914, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.019.h5\n",
      "Epoch 20/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.6982 - accuracy: 0.6413 - val_loss: 2.3308 - val_accuracy: 0.5209\n",
      "\n",
      "The average loss for epoch 19 is    1.71 and accuracy is    0.64.\n",
      "\n",
      "Epoch 00020: accuracy improved from 0.62914 to 0.63736, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.020.h5\n",
      "Epoch 21/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 34ms/step - loss: 1.6616 - accuracy: 0.6486 - val_loss: 2.1469 - val_accuracy: 0.5567\n",
      "\n",
      "The average loss for epoch 20 is    1.69 and accuracy is    0.64.\n",
      "\n",
      "Epoch 00021: accuracy improved from 0.63736 to 0.64166, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.021.h5\n",
      "Epoch 22/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 1.6356 - accuracy: 0.6565 - val_loss: 2.1309 - val_accuracy: 0.5597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The average loss for epoch 21 is    1.66 and accuracy is    0.65.\n",
      "\n",
      "Epoch 00022: accuracy improved from 0.64166 to 0.65052, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.022.h5\n",
      "Epoch 23/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.6079 - accuracy: 0.6627 - val_loss: 1.9555 - val_accuracy: 0.5892\n",
      "\n",
      "The average loss for epoch 22 is    1.64 and accuracy is    0.65.\n",
      "\n",
      "Epoch 00023: accuracy improved from 0.65052 to 0.65456, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.023.h5\n",
      "Epoch 24/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5958 - accuracy: 0.6675 - val_loss: 2.3197 - val_accuracy: 0.5455\n",
      "\n",
      "The average loss for epoch 23 is    1.63 and accuracy is    0.66.\n",
      "\n",
      "Epoch 00024: accuracy improved from 0.65456 to 0.65764, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.024.h5\n",
      "Epoch 25/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5688 - accuracy: 0.6729 - val_loss: 2.0057 - val_accuracy: 0.5777\n",
      "\n",
      "The average loss for epoch 24 is    1.61 and accuracy is    0.66.\n",
      "\n",
      "Epoch 00025: accuracy improved from 0.65764 to 0.66150, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.025.h5\n",
      "Epoch 26/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5719 - accuracy: 0.6736 - val_loss: 2.0292 - val_accuracy: 0.5769\n",
      "\n",
      "The average loss for epoch 25 is    1.60 and accuracy is    0.67.\n",
      "\n",
      "Epoch 00026: accuracy improved from 0.66150 to 0.66624, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.026.h5\n",
      "Epoch 27/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5620 - accuracy: 0.6798 - val_loss: 2.0055 - val_accuracy: 0.5907\n",
      "\n",
      "The average loss for epoch 26 is    1.59 and accuracy is    0.67.\n",
      "\n",
      "Epoch 00027: accuracy improved from 0.66624 to 0.67026, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.027.h5\n",
      "Epoch 28/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5380 - accuracy: 0.6861 - val_loss: 2.0507 - val_accuracy: 0.5845\n",
      "\n",
      "The average loss for epoch 27 is    1.57 and accuracy is    0.68.\n",
      "\n",
      "Epoch 00028: accuracy improved from 0.67026 to 0.67724, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.028.h5\n",
      "Epoch 29/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5240 - accuracy: 0.6869 - val_loss: 2.3734 - val_accuracy: 0.5397\n",
      "\n",
      "The average loss for epoch 28 is    1.55 and accuracy is    0.68.\n",
      "\n",
      "Epoch 00029: accuracy improved from 0.67724 to 0.67882, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.029.h5\n",
      "Epoch 30/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.5150 - accuracy: 0.6895 - val_loss: 2.1304 - val_accuracy: 0.5713\n",
      "\n",
      "The average loss for epoch 29 is    1.55 and accuracy is    0.68.\n",
      "\n",
      "Epoch 00030: accuracy improved from 0.67882 to 0.68098, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.030.h5\n",
      "Epoch 31/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.5165 - accuracy: 0.6928 - val_loss: 1.9339 - val_accuracy: 0.6026\n",
      "\n",
      "The average loss for epoch 30 is    1.54 and accuracy is    0.69.\n",
      "\n",
      "Epoch 00031: accuracy improved from 0.68098 to 0.68708, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.031.h5\n",
      "Epoch 32/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4911 - accuracy: 0.6973 - val_loss: 2.2335 - val_accuracy: 0.5608\n",
      "\n",
      "The average loss for epoch 31 is    1.52 and accuracy is    0.69.\n",
      "\n",
      "Epoch 00032: accuracy improved from 0.68708 to 0.68854, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.032.h5\n",
      "Epoch 33/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4773 - accuracy: 0.6990 - val_loss: 1.8409 - val_accuracy: 0.6235\n",
      "\n",
      "The average loss for epoch 32 is    1.51 and accuracy is    0.69.\n",
      "\n",
      "Epoch 00033: accuracy improved from 0.68854 to 0.69210, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.033.h5\n",
      "Epoch 34/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4816 - accuracy: 0.7016 - val_loss: 2.1362 - val_accuracy: 0.5712\n",
      "\n",
      "The average loss for epoch 33 is    1.50 and accuracy is    0.70.\n",
      "\n",
      "Epoch 00034: accuracy improved from 0.69210 to 0.69546, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.034.h5\n",
      "Epoch 35/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.4503 - accuracy: 0.7086 - val_loss: 2.0643 - val_accuracy: 0.5902\n",
      "\n",
      "The average loss for epoch 34 is    1.49 and accuracy is    0.69.\n",
      "\n",
      "Epoch 00035: accuracy did not improve from 0.69546\n",
      "Epoch 36/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4585 - accuracy: 0.7054 - val_loss: 2.0237 - val_accuracy: 0.5996\n",
      "\n",
      "The average loss for epoch 35 is    1.48 and accuracy is    0.70.\n",
      "\n",
      "Epoch 00036: accuracy improved from 0.69546 to 0.69976, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.036.h5\n",
      "Epoch 37/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4362 - accuracy: 0.7155 - val_loss: 1.9760 - val_accuracy: 0.5966\n",
      "\n",
      "The average loss for epoch 36 is    1.47 and accuracy is    0.70.\n",
      "\n",
      "Epoch 00037: accuracy improved from 0.69976 to 0.70428, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.037.h5\n",
      "Epoch 38/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4161 - accuracy: 0.7181 - val_loss: 2.0926 - val_accuracy: 0.5892\n",
      "\n",
      "The average loss for epoch 37 is    1.45 and accuracy is    0.71.\n",
      "\n",
      "Epoch 00038: accuracy improved from 0.70428 to 0.70924, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.038.h5\n",
      "Epoch 39/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4296 - accuracy: 0.7143 - val_loss: 2.3306 - val_accuracy: 0.5601\n",
      "\n",
      "The average loss for epoch 38 is    1.46 and accuracy is    0.71.\n",
      "\n",
      "Epoch 00039: accuracy did not improve from 0.70924\n",
      "Epoch 40/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4253 - accuracy: 0.7149 - val_loss: 2.0542 - val_accuracy: 0.5856\n",
      "\n",
      "The average loss for epoch 39 is    1.44 and accuracy is    0.71.\n",
      "\n",
      "Epoch 00040: accuracy improved from 0.70924 to 0.71094, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.040.h5\n",
      "Epoch 41/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.4000 - accuracy: 0.7225 - val_loss: 1.9451 - val_accuracy: 0.6066\n",
      "\n",
      "The average loss for epoch 40 is    1.43 and accuracy is    0.71.\n",
      "\n",
      "Epoch 00041: accuracy improved from 0.71094 to 0.71458, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.041.h5\n",
      "Epoch 42/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3845 - accuracy: 0.7294 - val_loss: 1.8620 - val_accuracy: 0.6179\n",
      "\n",
      "The average loss for epoch 41 is    1.42 and accuracy is    0.72.\n",
      "\n",
      "Epoch 00042: accuracy improved from 0.71458 to 0.71760, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.042.h5\n",
      "Epoch 43/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3983 - accuracy: 0.7219 - val_loss: 1.9795 - val_accuracy: 0.6073\n",
      "\n",
      "The average loss for epoch 42 is    1.43 and accuracy is    0.72.\n",
      "\n",
      "Epoch 00043: accuracy did not improve from 0.71760\n",
      "Epoch 44/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3878 - accuracy: 0.7248 - val_loss: 2.0832 - val_accuracy: 0.5969\n",
      "\n",
      "The average loss for epoch 43 is    1.42 and accuracy is    0.72.\n",
      "\n",
      "Epoch 00044: accuracy did not improve from 0.71760\n",
      "Epoch 45/90\n",
      "Learning rate:  0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3709 - accuracy: 0.7274 - val_loss: 2.1204 - val_accuracy: 0.5831\n",
      "\n",
      "The average loss for epoch 44 is    1.40 and accuracy is    0.72.\n",
      "\n",
      "Epoch 00045: accuracy improved from 0.71760 to 0.72048, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.045.h5\n",
      "Epoch 46/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3768 - accuracy: 0.7283 - val_loss: 2.0432 - val_accuracy: 0.6021\n",
      "\n",
      "The average loss for epoch 45 is    1.40 and accuracy is    0.72.\n",
      "\n",
      "Epoch 00046: accuracy improved from 0.72048 to 0.72274, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.046.h5\n",
      "Epoch 47/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3554 - accuracy: 0.7359 - val_loss: 2.0441 - val_accuracy: 0.5938\n",
      "\n",
      "The average loss for epoch 46 is    1.39 and accuracy is    0.73.\n",
      "\n",
      "Epoch 00047: accuracy improved from 0.72274 to 0.72652, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.047.h5\n",
      "Epoch 48/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3564 - accuracy: 0.7334 - val_loss: 1.8441 - val_accuracy: 0.6367\n",
      "\n",
      "The average loss for epoch 47 is    1.39 and accuracy is    0.73.\n",
      "\n",
      "Epoch 00048: accuracy did not improve from 0.72652\n",
      "Epoch 49/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3423 - accuracy: 0.7410 - val_loss: 2.1908 - val_accuracy: 0.5892\n",
      "\n",
      "The average loss for epoch 48 is    1.38 and accuracy is    0.73.\n",
      "\n",
      "Epoch 00049: accuracy improved from 0.72652 to 0.73132, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.049.h5\n",
      "Epoch 50/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.3417 - accuracy: 0.7384 - val_loss: 1.9310 - val_accuracy: 0.6240\n",
      "\n",
      "The average loss for epoch 49 is    1.37 and accuracy is    0.73.\n",
      "\n",
      "Epoch 00050: accuracy did not improve from 0.73132\n",
      "Epoch 51/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 1.3392 - accuracy: 0.7392 - val_loss: 1.9234 - val_accuracy: 0.6210\n",
      "\n",
      "The average loss for epoch 50 is    1.37 and accuracy is    0.73.\n",
      "\n",
      "Epoch 00051: accuracy did not improve from 0.73132\n",
      "Epoch 52/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3255 - accuracy: 0.7426 - val_loss: 1.9428 - val_accuracy: 0.6209\n",
      "\n",
      "The average loss for epoch 51 is    1.36 and accuracy is    0.73.\n",
      "\n",
      "Epoch 00052: accuracy improved from 0.73132 to 0.73440, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.052.h5\n",
      "Epoch 53/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3245 - accuracy: 0.7422 - val_loss: 2.0456 - val_accuracy: 0.6040\n",
      "\n",
      "The average loss for epoch 52 is    1.35 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00053: accuracy improved from 0.73440 to 0.73586, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.053.h5\n",
      "Epoch 54/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3086 - accuracy: 0.7499 - val_loss: 2.0386 - val_accuracy: 0.6049\n",
      "\n",
      "The average loss for epoch 53 is    1.35 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00054: accuracy improved from 0.73586 to 0.73804, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.054.h5\n",
      "Epoch 55/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3125 - accuracy: 0.7454 - val_loss: 1.7879 - val_accuracy: 0.6389\n",
      "\n",
      "The average loss for epoch 54 is    1.35 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00055: accuracy did not improve from 0.73804\n",
      "Epoch 56/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3107 - accuracy: 0.7509 - val_loss: 1.9508 - val_accuracy: 0.6179\n",
      "\n",
      "The average loss for epoch 55 is    1.34 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00056: accuracy improved from 0.73804 to 0.74166, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.056.h5\n",
      "Epoch 57/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3049 - accuracy: 0.7509 - val_loss: 2.0090 - val_accuracy: 0.6084\n",
      "\n",
      "The average loss for epoch 56 is    1.34 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00057: accuracy did not improve from 0.74166\n",
      "Epoch 58/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2993 - accuracy: 0.7508 - val_loss: 1.9111 - val_accuracy: 0.6248\n",
      "\n",
      "The average loss for epoch 57 is    1.33 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00058: accuracy did not improve from 0.74166\n",
      "Epoch 59/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.3036 - accuracy: 0.7489 - val_loss: 1.9608 - val_accuracy: 0.6188\n",
      "\n",
      "The average loss for epoch 58 is    1.33 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00059: accuracy improved from 0.74166 to 0.74232, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.059.h5\n",
      "Epoch 60/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.2989 - accuracy: 0.7485 - val_loss: 1.9099 - val_accuracy: 0.6298\n",
      "\n",
      "The average loss for epoch 59 is    1.33 and accuracy is    0.74.\n",
      "\n",
      "Epoch 00060: accuracy improved from 0.74232 to 0.74256, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.060.h5\n",
      "Epoch 61/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2685 - accuracy: 0.7592 - val_loss: 2.0178 - val_accuracy: 0.6114\n",
      "\n",
      "The average loss for epoch 60 is    1.31 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00061: accuracy improved from 0.74256 to 0.74852, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.061.h5\n",
      "Epoch 62/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2820 - accuracy: 0.7587 - val_loss: 1.8769 - val_accuracy: 0.6291\n",
      "\n",
      "The average loss for epoch 61 is    1.31 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00062: accuracy improved from 0.74852 to 0.74866, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.062.h5\n",
      "Epoch 63/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2685 - accuracy: 0.7584 - val_loss: 1.8097 - val_accuracy: 0.6492\n",
      "\n",
      "The average loss for epoch 62 is    1.31 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00063: accuracy did not improve from 0.74866\n",
      "Epoch 64/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2711 - accuracy: 0.7586 - val_loss: 1.9683 - val_accuracy: 0.6234\n",
      "\n",
      "The average loss for epoch 63 is    1.30 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00064: accuracy improved from 0.74866 to 0.75140, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.064.h5\n",
      "Epoch 65/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2695 - accuracy: 0.7576 - val_loss: 1.9311 - val_accuracy: 0.6303\n",
      "\n",
      "The average loss for epoch 64 is    1.30 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00065: accuracy did not improve from 0.75140\n",
      "Epoch 66/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2574 - accuracy: 0.7611 - val_loss: 2.0207 - val_accuracy: 0.6172\n",
      "\n",
      "The average loss for epoch 65 is    1.29 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00066: accuracy did not improve from 0.75140\n",
      "Epoch 67/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.2620 - accuracy: 0.7625 - val_loss: 1.8852 - val_accuracy: 0.6283\n",
      "\n",
      "The average loss for epoch 66 is    1.29 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00067: accuracy improved from 0.75140 to 0.75226, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.067.h5\n",
      "Epoch 68/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2597 - accuracy: 0.7626 - val_loss: 2.1767 - val_accuracy: 0.5918\n",
      "\n",
      "The average loss for epoch 67 is    1.29 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00068: accuracy improved from 0.75226 to 0.75582, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.068.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.2652 - accuracy: 0.7600 - val_loss: 1.9512 - val_accuracy: 0.6301\n",
      "\n",
      "The average loss for epoch 68 is    1.29 and accuracy is    0.75.\n",
      "\n",
      "Epoch 00069: accuracy did not improve from 0.75582\n",
      "Epoch 70/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2474 - accuracy: 0.7674 - val_loss: 2.2361 - val_accuracy: 0.5842\n",
      "\n",
      "The average loss for epoch 69 is    1.27 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00070: accuracy improved from 0.75582 to 0.76040, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.070.h5\n",
      "Epoch 71/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 1.2362 - accuracy: 0.7674 - val_loss: 1.8856 - val_accuracy: 0.6368\n",
      "\n",
      "The average loss for epoch 70 is    1.27 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00071: accuracy did not improve from 0.76040\n",
      "Epoch 72/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2261 - accuracy: 0.7721 - val_loss: 2.0640 - val_accuracy: 0.6164\n",
      "\n",
      "The average loss for epoch 71 is    1.27 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00072: accuracy did not improve from 0.76040\n",
      "Epoch 73/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2198 - accuracy: 0.7734 - val_loss: 1.9594 - val_accuracy: 0.6228\n",
      "\n",
      "The average loss for epoch 72 is    1.26 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00073: accuracy improved from 0.76040 to 0.76294, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.073.h5\n",
      "Epoch 74/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2175 - accuracy: 0.7753 - val_loss: 1.9801 - val_accuracy: 0.6216\n",
      "\n",
      "The average loss for epoch 73 is    1.26 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00074: accuracy did not improve from 0.76294\n",
      "Epoch 75/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2172 - accuracy: 0.7758 - val_loss: 2.0753 - val_accuracy: 0.6114\n",
      "\n",
      "The average loss for epoch 74 is    1.26 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00075: accuracy did not improve from 0.76294\n",
      "Epoch 76/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2289 - accuracy: 0.7680 - val_loss: 2.0090 - val_accuracy: 0.6239\n",
      "\n",
      "The average loss for epoch 75 is    1.26 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00076: accuracy did not improve from 0.76294\n",
      "Epoch 77/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2186 - accuracy: 0.7709 - val_loss: 1.9892 - val_accuracy: 0.6278\n",
      "\n",
      "The average loss for epoch 76 is    1.25 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00077: accuracy improved from 0.76294 to 0.76326, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.077.h5\n",
      "Epoch 78/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2102 - accuracy: 0.7759 - val_loss: 2.0445 - val_accuracy: 0.6182\n",
      "\n",
      "The average loss for epoch 77 is    1.24 and accuracy is    0.77.\n",
      "\n",
      "Epoch 00078: accuracy improved from 0.76326 to 0.76750, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.078.h5\n",
      "Epoch 79/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 1.2248 - accuracy: 0.7705 - val_loss: 1.8998 - val_accuracy: 0.6516\n",
      "\n",
      "The average loss for epoch 78 is    1.25 and accuracy is    0.76.\n",
      "\n",
      "Epoch 00079: accuracy did not improve from 0.76750\n",
      "Epoch 80/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.2051 - accuracy: 0.7762 - val_loss: 2.0159 - val_accuracy: 0.6152\n",
      "\n",
      "The average loss for epoch 79 is    1.23 and accuracy is    0.77.\n",
      "\n",
      "Epoch 00080: accuracy improved from 0.76750 to 0.76902, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.080.h5\n",
      "Epoch 81/90\n",
      "Learning rate:  0.001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.1972 - accuracy: 0.7798 - val_loss: 1.9454 - val_accuracy: 0.6281\n",
      "\n",
      "The average loss for epoch 80 is    1.23 and accuracy is    0.77.\n",
      "\n",
      "Epoch 00081: accuracy improved from 0.76902 to 0.77038, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.081.h5\n",
      "Epoch 82/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.0478 - accuracy: 0.8300 - val_loss: 1.5228 - val_accuracy: 0.7151\n",
      "\n",
      "The average loss for epoch 81 is    1.01 and accuracy is    0.84.\n",
      "\n",
      "Epoch 00082: accuracy improved from 0.77038 to 0.84086, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.082.h5\n",
      "Epoch 83/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.9259 - accuracy: 0.8624 - val_loss: 1.4859 - val_accuracy: 0.7242\n",
      "\n",
      "The average loss for epoch 82 is    0.92 and accuracy is    0.86.\n",
      "\n",
      "Epoch 00083: accuracy improved from 0.84086 to 0.86212, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.083.h5\n",
      "Epoch 84/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8821 - accuracy: 0.8731 - val_loss: 1.4820 - val_accuracy: 0.7255\n",
      "\n",
      "The average loss for epoch 83 is    0.88 and accuracy is    0.87.\n",
      "\n",
      "Epoch 00084: accuracy improved from 0.86212 to 0.87402, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.084.h5\n",
      "Epoch 85/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8461 - accuracy: 0.8818 - val_loss: 1.4691 - val_accuracy: 0.7315\n",
      "\n",
      "The average loss for epoch 84 is    0.85 and accuracy is    0.88.\n",
      "\n",
      "Epoch 00085: accuracy improved from 0.87402 to 0.88078, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.085.h5\n",
      "Epoch 86/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8206 - accuracy: 0.8923 - val_loss: 1.4756 - val_accuracy: 0.7296\n",
      "\n",
      "The average loss for epoch 85 is    0.82 and accuracy is    0.89.\n",
      "\n",
      "Epoch 00086: accuracy improved from 0.88078 to 0.88904, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.086.h5\n",
      "Epoch 87/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.8038 - accuracy: 0.8913 - val_loss: 1.4719 - val_accuracy: 0.7288\n",
      "\n",
      "The average loss for epoch 86 is    0.80 and accuracy is    0.89.\n",
      "\n",
      "Epoch 00087: accuracy improved from 0.88904 to 0.89000, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.087.h5\n",
      "Epoch 88/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7764 - accuracy: 0.8966 - val_loss: 1.4754 - val_accuracy: 0.7315\n",
      "\n",
      "The average loss for epoch 87 is    0.79 and accuracy is    0.89.\n",
      "\n",
      "Epoch 00088: accuracy improved from 0.89000 to 0.89386, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.088.h5\n",
      "Epoch 89/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 56s 35ms/step - loss: 0.7650 - accuracy: 0.8991 - val_loss: 1.4797 - val_accuracy: 0.7319\n",
      "\n",
      "The average loss for epoch 88 is    0.77 and accuracy is    0.90.\n",
      "\n",
      "Epoch 00089: accuracy improved from 0.89386 to 0.89766, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.089.h5\n",
      "Epoch 90/90\n",
      "Learning rate:  0.0001\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.7487 - accuracy: 0.9017 - val_loss: 1.4800 - val_accuracy: 0.7276\n",
      "\n",
      "The average loss for epoch 89 is    0.75 and accuracy is    0.90.\n",
      "\n",
      "Epoch 00090: accuracy improved from 0.89766 to 0.89972, saving model to /home/aastha/cifar100/saved_models/cifar100_ResNet56v2_model.090.h5\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 1.4800 - accuracy: 0.7276\n",
      "Test loss: 1.479983925819397\n",
      "Test accuracy: 0.7275999784469604\n",
      "\n",
      "Loss list:\n",
      " [4.354527950286865, 3.400479316711426, 2.9953227043151855, 2.7454111576080322, 2.5585830211639404, 2.4237558841705322, 2.3060660362243652, 2.212228536605835, 2.1375606060028076, 2.0744447708129883, 2.0170352458953857, 1.9673815965652466, 1.9224936962127686, 1.8751758337020874, 1.8506622314453125, 1.8102837800979614, 1.786062240600586, 1.7487245798110962, 1.7311265468597412, 1.7088587284088135, 1.6903150081634521, 1.6598488092422485, 1.6449562311172485, 1.6305482387542725, 1.6131714582443237, 1.5984195470809937, 1.5902143716812134, 1.5679959058761597, 1.5533462762832642, 1.5478571653366089, 1.5358706712722778, 1.5205117464065552, 1.5078368186950684, 1.50054931640625, 1.4894739389419556, 1.4785270690917969, 1.4709906578063965, 1.4528892040252686, 1.4555472135543823, 1.4412387609481812, 1.4301366806030273, 1.4229873418807983, 1.426887035369873, 1.4155056476593018, 1.3996039628982544, 1.4011038541793823, 1.3890528678894043, 1.3863571882247925, 1.382576823234558, 1.3737256526947021, 1.3670121431350708, 1.3568445444107056, 1.3537932634353638, 1.3492780923843384, 1.345986247062683, 1.3441206216812134, 1.3393173217773438, 1.3291200399398804, 1.3261041641235352, 1.3263604640960693, 1.310044288635254, 1.307587742805481, 1.3054487705230713, 1.2990057468414307, 1.3001959323883057, 1.293593168258667, 1.2945903539657593, 1.288596749305725, 1.2881059646606445, 1.2728312015533447, 1.2722634077072144, 1.2698665857315063, 1.2599434852600098, 1.2638776302337646, 1.257699966430664, 1.2594250440597534, 1.249159336090088, 1.2427349090576172, 1.2511464357376099, 1.23470938205719, 1.2317734956741333, 1.0060724020004272, 0.9241074323654175, 0.8802949786186218, 0.847652018070221, 0.8210837244987488, 0.804374635219574, 0.7858693599700928, 0.766262948513031, 0.7506616115570068] \n",
      "Accuracy list:\n",
      " [0.1410599946975708, 0.25496000051498413, 0.3251599967479706, 0.3805600106716156, 0.42215999960899353, 0.45254001021385193, 0.4810999929904938, 0.5048800110816956, 0.5222799777984619, 0.5413200259208679, 0.5537400245666504, 0.567359983921051, 0.580079972743988, 0.5887799859046936, 0.599399983882904, 0.6088600158691406, 0.6138799786567688, 0.6261000037193298, 0.6291400194168091, 0.6373599767684937, 0.6416599750518799, 0.6505200266838074, 0.6545600295066833, 0.6576399803161621, 0.6614999771118164, 0.6662399768829346, 0.6702600121498108, 0.6772400140762329, 0.678820013999939, 0.6809800267219543, 0.6870800256729126, 0.688539981842041, 0.6920999884605408, 0.6954600214958191, 0.6948999762535095, 0.6997600197792053, 0.7042800188064575, 0.7092400193214417, 0.7067999839782715, 0.7109400033950806, 0.7145799994468689, 0.7175999879837036, 0.7153000235557556, 0.7166399955749512, 0.7204800248146057, 0.7227399945259094, 0.7265200018882751, 0.725820004940033, 0.7313200235366821, 0.7304800152778625, 0.7311800122261047, 0.7343999743461609, 0.7358599901199341, 0.7380399703979492, 0.7370399832725525, 0.7416599988937378, 0.7399799823760986, 0.7414600253105164, 0.7423200011253357, 0.7425600290298462, 0.748520016670227, 0.7486600279808044, 0.7472599744796753, 0.7513999938964844, 0.7491199970245361, 0.7511399984359741, 0.7522600293159485, 0.7558199763298035, 0.7534199953079224, 0.7603999972343445, 0.7583199739456177, 0.7601000070571899, 0.762939989566803, 0.7605199813842773, 0.7623000144958496, 0.7602400183677673, 0.763260006904602, 0.7674999833106995, 0.763759970664978, 0.7690200209617615, 0.7703800201416016, 0.8408600091934204, 0.8621199727058411, 0.874019980430603, 0.8807799816131592, 0.8890399932861328, 0.8899999856948853, 0.8938599824905396, 0.8976600170135498, 0.8997200131416321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 23s 15ms/step - loss: 0.6759 - accuracy: 0.9204\n",
      "Train loss: 0.6759258508682251\n",
      "Train accuracy: 0.9203799962997437\n"
     ]
    }
   ],
   "source": [
    "# decides which resnet will get built here \n",
    "n = num \n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "print(\"****************************************************\")\n",
    "print(\"Model type is :\", model_type)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth , num_classes =100)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth, num_classes =100)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar100_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "log_loss_array = []; log_accuracy_array =[]\n",
    "\n",
    "class LossAndErrorPrintingCallback(tensorflow.keras.callbacks.Callback):\n",
    "    # def on_train_batch_end(self, batch, logs=None):\n",
    "    #     print(\"\\nFor batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
    "\n",
    "    # def on_test_batch_end(self, batch, logs=None):\n",
    "    #     print(\"\\nFor batch {}, loss is {:7.2f}.\".format(batch, logs[\"loss\"]))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        log_accuracy_array.append(logs[\"accuracy\"])\n",
    "        log_loss_array.append(logs[\"loss\"])\n",
    "        print(\"\\nThe average loss for epoch {} is {:7.2f} and accuracy is {:7.2f}.\".format(epoch, logs[\"loss\"], logs[\"accuracy\"]))\n",
    "\n",
    "callbacks = [LossAndErrorPrintingCallback(), checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "    model.save(\"ResNet56v2_model.h5\")\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"\\nLoss list:\\n\", log_loss_array , \"\\nAccuracy list:\\n\", log_accuracy_array)\n",
    "scores = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('Train loss:', scores[0])\n",
    "print('Train accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loss_list = np.array(\n",
    " [4.354527950286865, 3.400479316711426, 2.9953227043151855, 2.7454111576080322, 2.5585830211639404, 2.4237558841705322, 2.3060660362243652, 2.212228536605835, 2.1375606060028076, 2.0744447708129883, 2.0170352458953857, 1.9673815965652466, 1.9224936962127686, 1.8751758337020874, 1.8506622314453125, 1.8102837800979614, 1.786062240600586, 1.7487245798110962, 1.7311265468597412, 1.7088587284088135, 1.6903150081634521, 1.6598488092422485, 1.6449562311172485, 1.6305482387542725, 1.6131714582443237, 1.5984195470809937, 1.5902143716812134, 1.5679959058761597, 1.5533462762832642, 1.5478571653366089, 1.5358706712722778, 1.5205117464065552, 1.5078368186950684, 1.50054931640625, 1.4894739389419556, 1.4785270690917969, 1.4709906578063965, 1.4528892040252686, 1.4555472135543823, 1.4412387609481812, 1.4301366806030273, 1.4229873418807983, 1.426887035369873, 1.4155056476593018, 1.3996039628982544, 1.4011038541793823, 1.3890528678894043, 1.3863571882247925, 1.382576823234558, 1.3737256526947021, 1.3670121431350708, 1.3568445444107056, 1.3537932634353638, 1.3492780923843384, 1.345986247062683, 1.3441206216812134, 1.3393173217773438, 1.3291200399398804, 1.3261041641235352, 1.3263604640960693, 1.310044288635254, 1.307587742805481, 1.3054487705230713, 1.2990057468414307, 1.3001959323883057, 1.293593168258667, 1.2945903539657593, 1.288596749305725, 1.2881059646606445, 1.2728312015533447, 1.2722634077072144, 1.2698665857315063, 1.2599434852600098, 1.2638776302337646, 1.257699966430664, 1.2594250440597534, 1.249159336090088, 1.2427349090576172, 1.2511464357376099, 1.23470938205719, 1.2317734956741333, 1.0060724020004272, 0.9241074323654175, 0.8802949786186218, 0.847652018070221, 0.8210837244987488, 0.804374635219574, 0.7858693599700928, 0.766262948513031, 0.7506616115570068] )\n",
    "Accuracy_list = np.array(\n",
    " [0.1410599946975708, 0.25496000051498413, 0.3251599967479706, 0.3805600106716156, 0.42215999960899353, 0.45254001021385193, 0.4810999929904938, 0.5048800110816956, 0.5222799777984619, 0.5413200259208679, 0.5537400245666504, 0.567359983921051, 0.580079972743988, 0.5887799859046936, 0.599399983882904, 0.6088600158691406, 0.6138799786567688, 0.6261000037193298, 0.6291400194168091, 0.6373599767684937, 0.6416599750518799, 0.6505200266838074, 0.6545600295066833, 0.6576399803161621, 0.6614999771118164, 0.6662399768829346, 0.6702600121498108, 0.6772400140762329, 0.678820013999939, 0.6809800267219543, 0.6870800256729126, 0.688539981842041, 0.6920999884605408, 0.6954600214958191, 0.6948999762535095, 0.6997600197792053, 0.7042800188064575, 0.7092400193214417, 0.7067999839782715, 0.7109400033950806, 0.7145799994468689, 0.7175999879837036, 0.7153000235557556, 0.7166399955749512, 0.7204800248146057, 0.7227399945259094, 0.7265200018882751, 0.725820004940033, 0.7313200235366821, 0.7304800152778625, 0.7311800122261047, 0.7343999743461609, 0.7358599901199341, 0.7380399703979492, 0.7370399832725525, 0.7416599988937378, 0.7399799823760986, 0.7414600253105164, 0.7423200011253357, 0.7425600290298462, 0.748520016670227, 0.7486600279808044, 0.7472599744796753, 0.7513999938964844, 0.7491199970245361, 0.7511399984359741, 0.7522600293159485, 0.7558199763298035, 0.7534199953079224, 0.7603999972343445, 0.7583199739456177, 0.7601000070571899, 0.762939989566803, 0.7605199813842773, 0.7623000144958496, 0.7602400183677673, 0.763260006904602, 0.7674999833106995, 0.763759970664978, 0.7690200209617615, 0.7703800201416016, 0.8408600091934204, 0.8621199727058411, 0.874019980430603, 0.8807799816131592, 0.8890399932861328, 0.8899999856948853, 0.8938599824905396, 0.8976600170135498, 0.8997200131416321])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0cbdd0ebe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(1, 90, num=90)\n",
    "y1 = Accuracy_list\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y1)  \n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"RESNETv20_70epochs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0cbdcc4630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.linspace(1, 90, num=90)\n",
    "y1 = Loss_list\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(x, y1)  \n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"RESNETv20_70epochs\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "Learning rate:  0.001\n",
      "1375/1563 [=========================>....] - ETA: 6s - loss: 1.2189 - accuracy: 0.7596"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-16b40b6487c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     callbacks=callbacks)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ResNet56v2_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Score trained model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3322\u001b[0;31m       \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3324\u001b[0m       raise TypeError(\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__get_cmp_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;34m\"\"\"Returns a hashable eq-comparable key for `self`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;31m# TODO(b/133606651): Decide whether to cache this value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_serialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m__make_cmp_key\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aastha/.local/lib/python3.6/site-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    355\u001b[0m       ])\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__make_cmp_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "model.save(\"ResNet56v2_model.h5\")\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"\\nLoss list:\\n\", log_loss_array , \"\\nAccuracy list:\\n\", log_accuracy_array)\n",
    "scores = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('Train loss:', scores[0])\n",
    "print('Train accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "model.save(\"ResNet56v2_model.h5\")\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"\\nLoss list:\\n\", log_loss_array , \"\\nAccuracy list:\\n\", log_accuracy_array)\n",
    "scores = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('Train loss:', scores[0])\n",
    "print('Train accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "model.fit(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=epochs, verbose=1, workers=4,\n",
    "                    callbacks=callbacks)\n",
    "model.save(\"ResNet56v2_model.h5\")\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "print(\"\\nLoss list:\\n\", log_loss_array , \"\\nAccuracy list:\\n\", log_accuracy_array)\n",
    "scores = model.evaluate(x_train, y_train, verbose=1)\n",
    "print('Train loss:', scores[0])\n",
    "print('Train accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

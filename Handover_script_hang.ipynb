{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have imported tensorflow version : 2.4.1\n",
      "Keras version :  2.3.1\n",
      "CPU times: user 3.35 s, sys: 2.72 s, total: 6.07 s\n",
      "Wall time: 2.53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import glob\n",
    "import numpy as np \n",
    "import argparse \n",
    "import importlib\n",
    "import os \n",
    "from os import path\n",
    "import datetime\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import tensorflow as tf ; print(\"You have imported tensorflow version :\", tf.__version__)\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "import keras \n",
    "print(\"Keras version : \",keras.__version__)\n",
    "from tensorflow.keras.optimizers import Adam , Adagrad, Adadelta, RMSprop, SGD\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar100 , cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Image data generators for train test and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1198811 images belonging to 1000 classes.\n",
      "Found 62594 images belonging to 1000 classes.\n",
      "CPU times: user 1min 7s, sys: 31.6 s, total: 1min 38s\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "train_directory = '/home/aastha/imagenet/data/official_data/train/'\n",
    "batch_size = 64\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255.,  validation_split=0.05 ,   shear_range=0.2, zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "\n",
    "train_it = datagen.flow_from_directory( train_directory  , target_size=(224, 224), color_mode=\"rgb\", batch_size=batch_size, class_mode=\"categorical\", shuffle=True, seed=42, subset=\"training\")\n",
    "val_it = datagen.flow_from_directory(train_directory, target_size=(224, 224), color_mode=\"rgb\", batch_size=batch_size, class_mode=\"categorical\", shuffle=True, seed=42, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LR Scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30 µs, sys: 0 ns, total: 30 µs\n",
      "Wall time: 35.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "lr_callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "# did not use this in callbacks \n",
    "# anne = ReduceLROnPlateau(monitor='categorical_accuracy', factor=0.5, patience=1, verbose=1, min_lr=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of epoch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 µs, sys: 0 ns, total: 28 µs\n",
      "Wall time: 30.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs=None):\n",
    "            model.save(\"b0_210203_model_continued1.h5\") # the model is saved at the end of each epoch\n",
    "            print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,model.optimizer.lr.numpy()))\n",
    "            print(\"Loss :\", logs['loss'])\n",
    "            print(\"Accuracy :\",logs['categorical_accuracy'])\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpointing and tensorboard setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32 µs, sys: 0 ns, total: 32 µs\n",
      "Wall time: 34.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "checkpoint_dir = './training_checkpoints_210202_b0'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.7 ms, sys: 42.8 ms, total: 53.5 ms\n",
      "Wall time: 184 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "callbacks = [ \n",
    "    PrintLR(),\n",
    "    lr_callback,\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,save_best_only=True , verbose=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "Loading old model\n",
      "\n",
      "2/2 [==============================] - 23s 9s/step - loss: 0.9766 - categorical_accuracy: 0.7344 - val_loss: 1.5144 - val_categorical_accuracy: 0.6641\n",
      "\n",
      "Learning rate for epoch 1 is 9.999999747378752e-05\n",
      "Loss : 0.9375073313713074\n",
      "Accuracy : 0.75\n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.51444, saving model to ./training_checkpoints_210202_b0/ckpt_1\n",
      "INFO:tensorflow:Assets written to: ./training_checkpoints_210202_b0/ckpt_1/assets\n",
      "\n",
      "\n",
      "Loss vs epochs data - \n",
      " [0.9375073313713074]\n",
      "\n",
      "Accuracy vs epochs data - \n",
      " [0.75]\n",
      "\n",
      "CPU times: user 44.4 s, sys: 343 ms, total: 44.8 s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    if path.exists(\"b0_210203_model_continued.h5\"):\n",
    "        model = tf.keras.models.load_model(\"b0_210203_model_continued.h5\")\n",
    "        print(\"Loading old model\"); print()\n",
    "    else:\n",
    "        model = EfficientNetB0(weights=None)    \n",
    "        \n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True , name='categorical_crossentropy'), # change this to sparse=cce and metric to sparceCategoricalAccuracy \n",
    "        metrics=[tf.keras.metrics.CategoricalAccuracy()] )\n",
    "    \n",
    "    train_hist = model.fit_generator(\n",
    "        train_it,  epochs=1, verbose=1, callbacks= callbacks,steps_per_epoch=train_it.samples // batch_size,\n",
    "        validation_data= val_it,  validation_freq=1,validation_steps=val_it.samples // batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "    model.save(\"b0_210203_model_continued1.h5\")\n",
    "\n",
    "    print(); print(); print(\"Loss vs epochs data - \\n\", train_hist.history[\"loss\"] )\n",
    "    print()\n",
    "    print(\"Accuracy vs epochs data - \\n\", train_hist.history[\"categorical_accuracy\"] )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
